{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune-pytorch-model-gala-tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0947a261fd64c90a5d35745105ed4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1144981f60ef4880a42fab8b93da480e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10d6561741f04741ac9f3a4354a39d99",
              "IPY_MODEL_76df3702d1d644d48dd3a671b7397aa4"
            ]
          }
        },
        "1144981f60ef4880a42fab8b93da480e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10d6561741f04741ac9f3a4354a39d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b394d151b2a40ea9111ceb63eb69724",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 94,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 94,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20e9cd25c57f4e2f99953732c09dc4ee"
          }
        },
        "76df3702d1d644d48dd3a671b7397aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7935d21e73e643eb990749aca63e04c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 94/94 [01:41&lt;00:00,  1.07s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ac3df58337c4122a5a0c7994bcc0eb4"
          }
        },
        "6b394d151b2a40ea9111ceb63eb69724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20e9cd25c57f4e2f99953732c09dc4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7935d21e73e643eb990749aca63e04c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ac3df58337c4122a5a0c7994bcc0eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e816902d371478a93d8368a8247a584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ebef4044d3ae46ec932e62b855262624",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8927f58f70943708e436c624bad6ae1",
              "IPY_MODEL_2d7b82e23e9943098f56ed66f221df2a"
            ]
          }
        },
        "ebef4044d3ae46ec932e62b855262624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8927f58f70943708e436c624bad6ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98e0081580324a69acb309527208a528",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 51,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 51,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6e28cb691284fe1acab13265d4ea0d8"
          }
        },
        "2d7b82e23e9943098f56ed66f221df2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb497573b69745b090e1aa253e7b2c64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 51/51 [00:20&lt;00:00,  2.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbaa64a4bfed44baba0dc3732e61dec6"
          }
        },
        "98e0081580324a69acb309527208a528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6e28cb691284fe1acab13265d4ea0d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb497573b69745b090e1aa253e7b2c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbaa64a4bfed44baba0dc3732e61dec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN0-pvtH-SPw",
        "colab_type": "code",
        "outputId": "a727e858-305b-4210-ab5c-3d2dfbbe5b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! pip install -U tqdm\n",
        "\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"PyTorch Version: \", torch.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.43.0)\n",
            "PyTorch Version:  1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SZpl6rIjam1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b1d917fa-4d97-4deb-9ce1-2fc96631083e"
      },
      "source": [
        "! cp -r '/content/drive/My Drive/TEMP/gala_dataset.zip' /content/\n",
        "! unzip /content/gala_dataset.zip  -d /content/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gala_dataset.zip\n",
            "replace /content/dataset/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/dataset/Test Images/image9683.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace /content/dataset/Test Images/image9683.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPkDGOd1-Up-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "set some configuration variables\n",
        "'''\n",
        "\n",
        "valid_model_names = ['resnet', 'alexnet']\n",
        "\n",
        "train_csv_path = '/content/dataset/train.csv'\n",
        "test_csv_path = '/content/dataset/test.csv'\n",
        "train_images_dir = '/content/dataset/Train Images/'\n",
        "test_images_dir = '/content/dataset/Test Images/'\n",
        "\n",
        "\n",
        "model_name = 'resnet'\n",
        "\n",
        "num_classes = 4\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# set val_split = 0 for no validation\n",
        "val_split = 0.0\n",
        "# if dev_mode = True loads only a few samples\n",
        "dev_mode = False\n",
        "\n",
        "# feature_extract = False   ==> fine-tune the whole model \n",
        "# feature_extract = True    ==> only update the reshaped layer parameters\n",
        "feature_extract = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QwkGCeM-Xdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Define Transforms\n",
        "Define Dataset Class\n",
        "'''\n",
        "\n",
        "class galaDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transforms=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "        self.label_map = {'Decorationandsignage':0,\n",
        "                          'Food':1,\n",
        "                          'misc':2,\n",
        "                          'Attire':3}\n",
        "        try:\n",
        "            self.classes = df.Class.unique()\n",
        "            self.train = True\n",
        "        except:\n",
        "            self.train = False\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.__len__()\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_dir + self.df.loc[idx, 'Image']\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        if self.train:\n",
        "            # if its a train/val dataset\n",
        "            label = self.label_map[self.df.loc[idx, 'Class']]\n",
        "            return image, label\n",
        "        else:\n",
        "            # if its a test dataset\n",
        "            return image\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 244)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomAffine(degrees=[0,10]),\n",
        "        # transforms.RandomPerspective(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 244)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 244)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trq5oJQ5-YN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Prepare Dataset\n",
        "'''\n",
        "\n",
        "if dev_mode:\n",
        "    tr_df = pd.read_csv(train_csv_path).sample(100)\n",
        "else:\n",
        "    tr_df = pd.read_csv(train_csv_path)\n",
        "\n",
        "\n",
        "if val_split > 0:\n",
        "    tr_df, val_df = train_test_split(tr_df, test_size = val_split)\n",
        "    val_df = val_df.reset_index(drop=True)\n",
        "    tr_df = tr_df.reset_index(drop=True)\n",
        "    val_dataset = galaDataset(val_df, train_images_dir, data_transforms['val'])\n",
        "\n",
        "\n",
        "tr_dataset = galaDataset(tr_df, train_images_dir, data_transforms['train'])\n",
        "\n",
        "te_dataset = galaDataset(pd.read_csv(test_csv_path), test_images_dir, data_transforms['test'])\n",
        "\n",
        "\n",
        "if val_split > 0:\n",
        "    datasets_dict = {'train' : tr_dataset, 'test' : te_dataset, 'val' : val_dataset }\n",
        "else:\n",
        "    datasets_dict = {'train' : tr_dataset, 'test' : te_dataset,}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Ho2KEj-aA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "train_model parameters:\n",
        "    pytorch model\n",
        "    dictionary of dataset objects\n",
        "      ==> if validation dataset is passed with key 'val', validation is performer, else skipped\n",
        "    criterion : loss function\n",
        "    optimizer\n",
        "    number of epochs to train and validate for\n",
        "'''\n",
        "\n",
        "def train_model(model, datasets_dict, criterion, optimizer, batch_size, num_epochs = 25):\n",
        "    \n",
        "    since = time.time()\n",
        "\n",
        "    do_validation = (datasets_dict.get('val') != None)\n",
        "    \n",
        "    train_acc_hist = []\n",
        "    train_loss_hist = []\n",
        "\n",
        "    if do_validation:\n",
        "        val_acc_history = []\n",
        "        val_f1_history = []\n",
        "        val_dataloader = DataLoader(datasets_dict['val'], batch_size=batch_size, shuffle=True)\n",
        "        print('Validating on {} samples.'.format(datasets_dict['val'].__len__()))\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_acc = 0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        tr_dataloader = DataLoader(datasets_dict['train'], batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "        if do_validation:\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "            phases = ['train', 'val']\n",
        "            dataloaders = {'train' : tr_dataloader, 'val' : val_dataloader}\n",
        "        else:\n",
        "            phases = ['train']\n",
        "            dataloaders = {'train' : tr_dataloader}\n",
        "\n",
        "\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-'*10)\n",
        "\n",
        "        for phase in phases:\n",
        "            if phase == 'train':    model.train()\n",
        "            elif phase == 'val':    model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                \n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                if do_validation:\n",
        "                    val_preds.append(preds.cpu())\n",
        "                    val_labels.append(labels.cpu())\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "            if phase == 'train':\n",
        "                train_acc_hist.append(epoch_acc)\n",
        "                train_loss_hist.append(epoch_loss)\n",
        "\n",
        "        if do_validation:\n",
        "            val_f1 = get_f1(val_preds, val_labels)\n",
        "            print(\"val F1 : \", val_f1)\n",
        "            val_f1_history.append(val_f1)\n",
        "\n",
        "        print()\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    if do_validation:\n",
        "        print('Best val Acc: {:4f}'.format(best_acc))\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        metrics = {'val_acc_hist':val_acc_history, 'val_f1_hist':val_f1_history, 'train_acc_hist':train_acc_hist, 'train_loss_hist':train_loss_hist}\n",
        "    else:\n",
        "        metrics = {'train_acc_hist':train_acc_hist, 'train_loss_hist':train_loss_hist}\n",
        "    \n",
        "    return model, metrics\n",
        "\n",
        "\n",
        "def set_parameters_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, features_extract, use_pretrained=True):\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "    \n",
        "    _ = ['resnet', 'alexnet']\n",
        "    \n",
        "    if model_name == 'resnet':\n",
        "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
        "        set_parameters_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameters_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    else:\n",
        "        print('Invalid model name, exiting. . .') \n",
        "        exit()\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "\n",
        "def get_f1(val_preds, val_labels):\n",
        "    VP = []\n",
        "    VL = []\n",
        "    for l in [list(x.numpy()) for x in val_preds]: VP.extend(l)\n",
        "    for l in [list(x.numpy()) for x in val_labels]: VL.extend(l)\n",
        "    return f1_score(VL, VP, average='weighted')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNrU1sl7-e1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjxI9FBr-gVW",
        "colab_type": "code",
        "outputId": "b1d2fecc-5a04-4098-8466-8707f5a11e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    model_ft.cuda()\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model_ft = model_ft.to(device)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsjXgvt9Is25",
        "colab_type": "code",
        "outputId": "e73e713d-81ec-41f7-8b2f-bcdf98906f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name, end='')\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name, end='')\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "\n",
        "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t conv1.weight\t bn1.weight\t bn1.bias\t layer1.0.conv1.weight\t layer1.0.bn1.weight\t layer1.0.bn1.bias\t layer1.0.conv2.weight\t layer1.0.bn2.weight\t layer1.0.bn2.bias\t layer1.0.conv3.weight\t layer1.0.bn3.weight\t layer1.0.bn3.bias\t layer1.0.downsample.0.weight\t layer1.0.downsample.1.weight\t layer1.0.downsample.1.bias\t layer1.1.conv1.weight\t layer1.1.bn1.weight\t layer1.1.bn1.bias\t layer1.1.conv2.weight\t layer1.1.bn2.weight\t layer1.1.bn2.bias\t layer1.1.conv3.weight\t layer1.1.bn3.weight\t layer1.1.bn3.bias\t layer1.2.conv1.weight\t layer1.2.bn1.weight\t layer1.2.bn1.bias\t layer1.2.conv2.weight\t layer1.2.bn2.weight\t layer1.2.bn2.bias\t layer1.2.conv3.weight\t layer1.2.bn3.weight\t layer1.2.bn3.bias\t layer2.0.conv1.weight\t layer2.0.bn1.weight\t layer2.0.bn1.bias\t layer2.0.conv2.weight\t layer2.0.bn2.weight\t layer2.0.bn2.bias\t layer2.0.conv3.weight\t layer2.0.bn3.weight\t layer2.0.bn3.bias\t layer2.0.downsample.0.weight\t layer2.0.downsample.1.weight\t layer2.0.downsample.1.bias\t layer2.1.conv1.weight\t layer2.1.bn1.weight\t layer2.1.bn1.bias\t layer2.1.conv2.weight\t layer2.1.bn2.weight\t layer2.1.bn2.bias\t layer2.1.conv3.weight\t layer2.1.bn3.weight\t layer2.1.bn3.bias\t layer2.2.conv1.weight\t layer2.2.bn1.weight\t layer2.2.bn1.bias\t layer2.2.conv2.weight\t layer2.2.bn2.weight\t layer2.2.bn2.bias\t layer2.2.conv3.weight\t layer2.2.bn3.weight\t layer2.2.bn3.bias\t layer2.3.conv1.weight\t layer2.3.bn1.weight\t layer2.3.bn1.bias\t layer2.3.conv2.weight\t layer2.3.bn2.weight\t layer2.3.bn2.bias\t layer2.3.conv3.weight\t layer2.3.bn3.weight\t layer2.3.bn3.bias\t layer2.4.conv1.weight\t layer2.4.bn1.weight\t layer2.4.bn1.bias\t layer2.4.conv2.weight\t layer2.4.bn2.weight\t layer2.4.bn2.bias\t layer2.4.conv3.weight\t layer2.4.bn3.weight\t layer2.4.bn3.bias\t layer2.5.conv1.weight\t layer2.5.bn1.weight\t layer2.5.bn1.bias\t layer2.5.conv2.weight\t layer2.5.bn2.weight\t layer2.5.bn2.bias\t layer2.5.conv3.weight\t layer2.5.bn3.weight\t layer2.5.bn3.bias\t layer2.6.conv1.weight\t layer2.6.bn1.weight\t layer2.6.bn1.bias\t layer2.6.conv2.weight\t layer2.6.bn2.weight\t layer2.6.bn2.bias\t layer2.6.conv3.weight\t layer2.6.bn3.weight\t layer2.6.bn3.bias\t layer2.7.conv1.weight\t layer2.7.bn1.weight\t layer2.7.bn1.bias\t layer2.7.conv2.weight\t layer2.7.bn2.weight\t layer2.7.bn2.bias\t layer2.7.conv3.weight\t layer2.7.bn3.weight\t layer2.7.bn3.bias\t layer3.0.conv1.weight\t layer3.0.bn1.weight\t layer3.0.bn1.bias\t layer3.0.conv2.weight\t layer3.0.bn2.weight\t layer3.0.bn2.bias\t layer3.0.conv3.weight\t layer3.0.bn3.weight\t layer3.0.bn3.bias\t layer3.0.downsample.0.weight\t layer3.0.downsample.1.weight\t layer3.0.downsample.1.bias\t layer3.1.conv1.weight\t layer3.1.bn1.weight\t layer3.1.bn1.bias\t layer3.1.conv2.weight\t layer3.1.bn2.weight\t layer3.1.bn2.bias\t layer3.1.conv3.weight\t layer3.1.bn3.weight\t layer3.1.bn3.bias\t layer3.2.conv1.weight\t layer3.2.bn1.weight\t layer3.2.bn1.bias\t layer3.2.conv2.weight\t layer3.2.bn2.weight\t layer3.2.bn2.bias\t layer3.2.conv3.weight\t layer3.2.bn3.weight\t layer3.2.bn3.bias\t layer3.3.conv1.weight\t layer3.3.bn1.weight\t layer3.3.bn1.bias\t layer3.3.conv2.weight\t layer3.3.bn2.weight\t layer3.3.bn2.bias\t layer3.3.conv3.weight\t layer3.3.bn3.weight\t layer3.3.bn3.bias\t layer3.4.conv1.weight\t layer3.4.bn1.weight\t layer3.4.bn1.bias\t layer3.4.conv2.weight\t layer3.4.bn2.weight\t layer3.4.bn2.bias\t layer3.4.conv3.weight\t layer3.4.bn3.weight\t layer3.4.bn3.bias\t layer3.5.conv1.weight\t layer3.5.bn1.weight\t layer3.5.bn1.bias\t layer3.5.conv2.weight\t layer3.5.bn2.weight\t layer3.5.bn2.bias\t layer3.5.conv3.weight\t layer3.5.bn3.weight\t layer3.5.bn3.bias\t layer3.6.conv1.weight\t layer3.6.bn1.weight\t layer3.6.bn1.bias\t layer3.6.conv2.weight\t layer3.6.bn2.weight\t layer3.6.bn2.bias\t layer3.6.conv3.weight\t layer3.6.bn3.weight\t layer3.6.bn3.bias\t layer3.7.conv1.weight\t layer3.7.bn1.weight\t layer3.7.bn1.bias\t layer3.7.conv2.weight\t layer3.7.bn2.weight\t layer3.7.bn2.bias\t layer3.7.conv3.weight\t layer3.7.bn3.weight\t layer3.7.bn3.bias\t layer3.8.conv1.weight\t layer3.8.bn1.weight\t layer3.8.bn1.bias\t layer3.8.conv2.weight\t layer3.8.bn2.weight\t layer3.8.bn2.bias\t layer3.8.conv3.weight\t layer3.8.bn3.weight\t layer3.8.bn3.bias\t layer3.9.conv1.weight\t layer3.9.bn1.weight\t layer3.9.bn1.bias\t layer3.9.conv2.weight\t layer3.9.bn2.weight\t layer3.9.bn2.bias\t layer3.9.conv3.weight\t layer3.9.bn3.weight\t layer3.9.bn3.bias\t layer3.10.conv1.weight\t layer3.10.bn1.weight\t layer3.10.bn1.bias\t layer3.10.conv2.weight\t layer3.10.bn2.weight\t layer3.10.bn2.bias\t layer3.10.conv3.weight\t layer3.10.bn3.weight\t layer3.10.bn3.bias\t layer3.11.conv1.weight\t layer3.11.bn1.weight\t layer3.11.bn1.bias\t layer3.11.conv2.weight\t layer3.11.bn2.weight\t layer3.11.bn2.bias\t layer3.11.conv3.weight\t layer3.11.bn3.weight\t layer3.11.bn3.bias\t layer3.12.conv1.weight\t layer3.12.bn1.weight\t layer3.12.bn1.bias\t layer3.12.conv2.weight\t layer3.12.bn2.weight\t layer3.12.bn2.bias\t layer3.12.conv3.weight\t layer3.12.bn3.weight\t layer3.12.bn3.bias\t layer3.13.conv1.weight\t layer3.13.bn1.weight\t layer3.13.bn1.bias\t layer3.13.conv2.weight\t layer3.13.bn2.weight\t layer3.13.bn2.bias\t layer3.13.conv3.weight\t layer3.13.bn3.weight\t layer3.13.bn3.bias\t layer3.14.conv1.weight\t layer3.14.bn1.weight\t layer3.14.bn1.bias\t layer3.14.conv2.weight\t layer3.14.bn2.weight\t layer3.14.bn2.bias\t layer3.14.conv3.weight\t layer3.14.bn3.weight\t layer3.14.bn3.bias\t layer3.15.conv1.weight\t layer3.15.bn1.weight\t layer3.15.bn1.bias\t layer3.15.conv2.weight\t layer3.15.bn2.weight\t layer3.15.bn2.bias\t layer3.15.conv3.weight\t layer3.15.bn3.weight\t layer3.15.bn3.bias\t layer3.16.conv1.weight\t layer3.16.bn1.weight\t layer3.16.bn1.bias\t layer3.16.conv2.weight\t layer3.16.bn2.weight\t layer3.16.bn2.bias\t layer3.16.conv3.weight\t layer3.16.bn3.weight\t layer3.16.bn3.bias\t layer3.17.conv1.weight\t layer3.17.bn1.weight\t layer3.17.bn1.bias\t layer3.17.conv2.weight\t layer3.17.bn2.weight\t layer3.17.bn2.bias\t layer3.17.conv3.weight\t layer3.17.bn3.weight\t layer3.17.bn3.bias\t layer3.18.conv1.weight\t layer3.18.bn1.weight\t layer3.18.bn1.bias\t layer3.18.conv2.weight\t layer3.18.bn2.weight\t layer3.18.bn2.bias\t layer3.18.conv3.weight\t layer3.18.bn3.weight\t layer3.18.bn3.bias\t layer3.19.conv1.weight\t layer3.19.bn1.weight\t layer3.19.bn1.bias\t layer3.19.conv2.weight\t layer3.19.bn2.weight\t layer3.19.bn2.bias\t layer3.19.conv3.weight\t layer3.19.bn3.weight\t layer3.19.bn3.bias\t layer3.20.conv1.weight\t layer3.20.bn1.weight\t layer3.20.bn1.bias\t layer3.20.conv2.weight\t layer3.20.bn2.weight\t layer3.20.bn2.bias\t layer3.20.conv3.weight\t layer3.20.bn3.weight\t layer3.20.bn3.bias\t layer3.21.conv1.weight\t layer3.21.bn1.weight\t layer3.21.bn1.bias\t layer3.21.conv2.weight\t layer3.21.bn2.weight\t layer3.21.bn2.bias\t layer3.21.conv3.weight\t layer3.21.bn3.weight\t layer3.21.bn3.bias\t layer3.22.conv1.weight\t layer3.22.bn1.weight\t layer3.22.bn1.bias\t layer3.22.conv2.weight\t layer3.22.bn2.weight\t layer3.22.bn2.bias\t layer3.22.conv3.weight\t layer3.22.bn3.weight\t layer3.22.bn3.bias\t layer3.23.conv1.weight\t layer3.23.bn1.weight\t layer3.23.bn1.bias\t layer3.23.conv2.weight\t layer3.23.bn2.weight\t layer3.23.bn2.bias\t layer3.23.conv3.weight\t layer3.23.bn3.weight\t layer3.23.bn3.bias\t layer3.24.conv1.weight\t layer3.24.bn1.weight\t layer3.24.bn1.bias\t layer3.24.conv2.weight\t layer3.24.bn2.weight\t layer3.24.bn2.bias\t layer3.24.conv3.weight\t layer3.24.bn3.weight\t layer3.24.bn3.bias\t layer3.25.conv1.weight\t layer3.25.bn1.weight\t layer3.25.bn1.bias\t layer3.25.conv2.weight\t layer3.25.bn2.weight\t layer3.25.bn2.bias\t layer3.25.conv3.weight\t layer3.25.bn3.weight\t layer3.25.bn3.bias\t layer3.26.conv1.weight\t layer3.26.bn1.weight\t layer3.26.bn1.bias\t layer3.26.conv2.weight\t layer3.26.bn2.weight\t layer3.26.bn2.bias\t layer3.26.conv3.weight\t layer3.26.bn3.weight\t layer3.26.bn3.bias\t layer3.27.conv1.weight\t layer3.27.bn1.weight\t layer3.27.bn1.bias\t layer3.27.conv2.weight\t layer3.27.bn2.weight\t layer3.27.bn2.bias\t layer3.27.conv3.weight\t layer3.27.bn3.weight\t layer3.27.bn3.bias\t layer3.28.conv1.weight\t layer3.28.bn1.weight\t layer3.28.bn1.bias\t layer3.28.conv2.weight\t layer3.28.bn2.weight\t layer3.28.bn2.bias\t layer3.28.conv3.weight\t layer3.28.bn3.weight\t layer3.28.bn3.bias\t layer3.29.conv1.weight\t layer3.29.bn1.weight\t layer3.29.bn1.bias\t layer3.29.conv2.weight\t layer3.29.bn2.weight\t layer3.29.bn2.bias\t layer3.29.conv3.weight\t layer3.29.bn3.weight\t layer3.29.bn3.bias\t layer3.30.conv1.weight\t layer3.30.bn1.weight\t layer3.30.bn1.bias\t layer3.30.conv2.weight\t layer3.30.bn2.weight\t layer3.30.bn2.bias\t layer3.30.conv3.weight\t layer3.30.bn3.weight\t layer3.30.bn3.bias\t layer3.31.conv1.weight\t layer3.31.bn1.weight\t layer3.31.bn1.bias\t layer3.31.conv2.weight\t layer3.31.bn2.weight\t layer3.31.bn2.bias\t layer3.31.conv3.weight\t layer3.31.bn3.weight\t layer3.31.bn3.bias\t layer3.32.conv1.weight\t layer3.32.bn1.weight\t layer3.32.bn1.bias\t layer3.32.conv2.weight\t layer3.32.bn2.weight\t layer3.32.bn2.bias\t layer3.32.conv3.weight\t layer3.32.bn3.weight\t layer3.32.bn3.bias\t layer3.33.conv1.weight\t layer3.33.bn1.weight\t layer3.33.bn1.bias\t layer3.33.conv2.weight\t layer3.33.bn2.weight\t layer3.33.bn2.bias\t layer3.33.conv3.weight\t layer3.33.bn3.weight\t layer3.33.bn3.bias\t layer3.34.conv1.weight\t layer3.34.bn1.weight\t layer3.34.bn1.bias\t layer3.34.conv2.weight\t layer3.34.bn2.weight\t layer3.34.bn2.bias\t layer3.34.conv3.weight\t layer3.34.bn3.weight\t layer3.34.bn3.bias\t layer3.35.conv1.weight\t layer3.35.bn1.weight\t layer3.35.bn1.bias\t layer3.35.conv2.weight\t layer3.35.bn2.weight\t layer3.35.bn2.bias\t layer3.35.conv3.weight\t layer3.35.bn3.weight\t layer3.35.bn3.bias\t layer4.0.conv1.weight\t layer4.0.bn1.weight\t layer4.0.bn1.bias\t layer4.0.conv2.weight\t layer4.0.bn2.weight\t layer4.0.bn2.bias\t layer4.0.conv3.weight\t layer4.0.bn3.weight\t layer4.0.bn3.bias\t layer4.0.downsample.0.weight\t layer4.0.downsample.1.weight\t layer4.0.downsample.1.bias\t layer4.1.conv1.weight\t layer4.1.bn1.weight\t layer4.1.bn1.bias\t layer4.1.conv2.weight\t layer4.1.bn2.weight\t layer4.1.bn2.bias\t layer4.1.conv3.weight\t layer4.1.bn3.weight\t layer4.1.bn3.bias\t layer4.2.conv1.weight\t layer4.2.bn1.weight\t layer4.2.bn1.bias\t layer4.2.conv2.weight\t layer4.2.bn2.weight\t layer4.2.bn2.bias\t layer4.2.conv3.weight\t layer4.2.bn3.weight\t layer4.2.bn3.bias\t fc.weight\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TqkWM85fHBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "a0947a261fd64c90a5d35745105ed4d6",
            "1144981f60ef4880a42fab8b93da480e",
            "10d6561741f04741ac9f3a4354a39d99",
            "76df3702d1d644d48dd3a671b7397aa4",
            "6b394d151b2a40ea9111ceb63eb69724",
            "20e9cd25c57f4e2f99953732c09dc4ee",
            "7935d21e73e643eb990749aca63e04c0",
            "0ac3df58337c4122a5a0c7994bcc0eb4"
          ]
        },
        "outputId": "4160c2ac-11bd-41de-fa2a-3fe6b1f85feb"
      },
      "source": [
        "# run the training loop\n",
        "model_ft, hist = train_model(model_ft, datasets_dict, criterion, optimizer_ft, batch_size, num_epochs=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0947a261fd64c90a5d35745105ed4d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=94.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train Loss: 0.1439 Acc: 0.9544\n",
            "\n",
            "Training complete in 1m 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F15ocXwbMs7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "300599dc-a93f-438b-ee15-df28a1564e12"
      },
      "source": [
        "'''\n",
        "Pickle model and training metrics on drive\n",
        "'''\n",
        "# import pickle\n",
        "# with open('/content/drive/My Drive/TEMP/gala_image_tagging_hist.pickle', 'wb') as f:\n",
        "#     pickle.dump(hist, f)\n",
        "# with open('/content/drive/My Drive/TEMP/gala_image_tagging_model.pickle', 'wb') as f:\n",
        "#     pickle.dump(model_ft, f)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPickle model and training metrics on drive\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKg7YD8nNTnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Un-Pickle saved entities\n",
        "'''\n",
        "# import pickle\n",
        "# with open('/content/drive/My Drive/TEMP/gala_image_tagging_val_accu_hist.pickle', 'rb') as f:\n",
        "#   hist = pickle.load(f)\n",
        "# with open('/content/drive/My Drive/TEMP/gala_image_tagging_model.pickle', 'rb') as f:\n",
        "#   model_ft = pickle.load(f)\n",
        "\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda\")\n",
        "#     print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "#     print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "#     model_ft.cuda()\n",
        "# else:\n",
        "#     print('No GPU available, using the CPU instead.')\n",
        "#     device = torch.device(\"cpu\")\n",
        "\n",
        "# model_ft = model_ft.to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZylgIDI2DO",
        "colab_type": "text"
      },
      "source": [
        "#**GET TEST PREDICTIONS** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiyVis7uWcPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAsPGlKH4fZ",
        "colab_type": "code",
        "outputId": "e725f0f9-ad7a-454b-e624-c1c356d13b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "4e816902d371478a93d8368a8247a584",
            "ebef4044d3ae46ec932e62b855262624",
            "d8927f58f70943708e436c624bad6ae1",
            "2d7b82e23e9943098f56ed66f221df2a",
            "98e0081580324a69acb309527208a528",
            "b6e28cb691284fe1acab13265d4ea0d8",
            "eb497573b69745b090e1aa253e7b2c64",
            "cbaa64a4bfed44baba0dc3732e61dec6"
          ]
        }
      },
      "source": [
        "print('Generating predictions for {} samples'.format(te_dataset.__len__()))\n",
        "\n",
        "te_dataloader = DataLoader(te_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model_ft.eval()\n",
        "test_preds = None\n",
        "\n",
        "for inputs in tqdm(te_dataloader):\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_ft(inputs)\n",
        "\n",
        "        if test_preds is None:\n",
        "            test_preds = outputs.data.cpu()\n",
        "        else:\n",
        "            test_preds = torch.cat((test_preds, outputs.data.cpu()), dim=0)\n",
        "    \n",
        "res = test_preds.argmax(dim=1)\n",
        "te_df = pd.read_csv(test_csv_path)\n",
        "te_df['Class'] = res\n",
        "\n",
        "label_map = {\n",
        "    0:'Decorationandsignage',\n",
        "    1:'Food',\n",
        "    2:'misc',\n",
        "    3:'Attire'}\n",
        "te_df['Class'] = te_df.Class.map(label_map)\n",
        "\n",
        "\n",
        "te_df.to_csv('/content/gala_submission_resnet152_6-epoch_64-batch_lesser-aug.csv', index=False)\n",
        "hist"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating predictions for 3219 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e816902d371478a93d8368a8247a584",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=51.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_acc_hist': [tensor(0.9544, device='cuda:0', dtype=torch.float64)],\n",
              " 'train_loss_hist': [0.14388068470392223]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYWkIzmPkkam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77e1c8a5-37eb-440d-c3a4-d5c13f0dccd1"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gala_submission_resnet152_3-epoch_64-batch_lesser-aug.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtQn4GQbiLjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}