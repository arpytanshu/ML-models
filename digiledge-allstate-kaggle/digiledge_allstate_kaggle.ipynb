{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digiledge-allstate-kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCFjTyrNFdeB",
        "colab_type": "code",
        "outputId": "cffdd9eb-345f-42ff-e388-e2d5cdff9068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcbhucaoFfKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_json_path = '/content/drive/My Drive/TEMP/kaggle.json'\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/TEMP/\"\n",
        "\n",
        "!kaggle competitions download -c allstate-claims-severity\n",
        "!cp *.zip \"/content/drive/My Drive/TEMP/digiledge-allstate-kaggle/\"\n",
        "!unzip \"/content/drive/My Drive/TEMP/digiledge-allstate-kaggle/*.zip\" -d \"/content/drive/My Drive/TEMP/digiledge-allstate-kaggle/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnophKkRQk2Y",
        "colab_type": "text"
      },
      "source": [
        "### **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndojCCq-QjyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2FHV3vFPptM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "objects_dir = \"/content/drive/My Drive/TEMP/digiledge-allstate-kaggle/objects/\"  # to hold objects created on the fly\n",
        "drive_data_dir = '/content/drive/My Drive/TEMP/digiledge-allstate-kaggle/'\n",
        "\n",
        "train_data_path = drive_data_dir+'train.csv'\n",
        "test_data_path = drive_data_dir+'test.csv'\n",
        "submission_csv_path = drive_data_dir+'sample_submission.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wtma8dsQrcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Label Encode all categorical features\n",
        "def get_labelEncoded_dataframes(drive_data_dir, object_dir):\n",
        "  '''\n",
        "  creates a label encoded dataframe out of the categorical features using sklearns's LabelEncoder\n",
        "  saves new dataframe in object_dir\n",
        "  skips creating new dataframe if already exists\n",
        "  '''\n",
        "  try:\n",
        "    train_data = pd.read_csv(objects_dir+'train_label_encoded.csv')\n",
        "    test_data = pd.read_csv(objects_dir + 'test_label_encoded.csv')\n",
        "  except:\n",
        "    print('Label Encoding categorical features . . .')\n",
        "    train_data = pd.read_csv(drive_data_dir+'train.csv')\n",
        "    test_data = pd.read_csv(drive_data_dir+'test.csv')\n",
        "    cat_cols = [x for x in train_data.columns if x.startswith('cat')]\n",
        "\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        train_data[col] = le.fit_transform(train_data[col])\n",
        "        # update::\n",
        "        # Test data had some values in some cateogorical features that were unseen in train data\n",
        "        # the next 2 lines fix that :|\n",
        "        test_data[col] = test_data[col].map(lambda s: 'UNK' if s not in le.classes_ else s)\n",
        "        le.classes_ = np.append(le.classes_, 'UNK')\n",
        "        test_data[col] = le.transform(test_data[col])\n",
        "    # save encoded train and test dataFrames to objects dir\n",
        "    print('Saved Label Encoded features to', objects_dir + '*.csv')\n",
        "    train_data.to_csv(objects_dir + 'train_label_encoded.csv', index=False)\n",
        "    test_data.to_csv(objects_dir + 'test_label_encoded.csv', index=False)\n",
        "  return train_data, test_data\n",
        "\n",
        "\n",
        "\n",
        "train_data, test_data = get_labelEncoded_dataframes(drive_data_dir, objects_dir)\n",
        "submission = pd.read_csv(submission_csv_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zbpzjlISKZI",
        "colab_type": "text"
      },
      "source": [
        "Since we will use train data pretty frequently to select features and build our model, using a handy name.  \n",
        "\"X\" & \"Y\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx8am2GXSJy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_data.iloc[:,1:-1]\n",
        "Y = train_data.iloc[:,-1]\n",
        "\n",
        "\n",
        "# get categorical and continuous features names\n",
        "cat_cols = [x for x in train_data.columns if x.startswith('cat')]\n",
        "cont_cols = [x for x in train_data.columns if x.startswith('cont')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofjrt_fkSkNO",
        "colab_type": "text"
      },
      "source": [
        "# <br>  \n",
        "  \n",
        "### We make a benchmark xgboost model to see benchmark scores as we make changes to features.  \n",
        "### This will validate the features using a 5 fold CV\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MjO4_EYS5W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def benchmark_xgb(X, Y, num_folds=5):\n",
        "    dtrain = xgb.DMatrix(X, Y)\n",
        "    params = {'eta': 0.01, 'seed':0, 'subsample': 0.5, 'colsample_bytree': 0.5, \n",
        "             'objective': 'reg:squarederror', 'max_depth':6, 'min_child_weight':3} \n",
        "    # Grid Search CV optimized settings\n",
        "    num_rounds = 1000\n",
        "    res = xgb.cv(params, dtrain, num_rounds, num_folds, metrics='mae' )\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPHjssvJbCvD",
        "colab_type": "text"
      },
      "source": [
        "### Lets see MAE scores using only categorical features and only continuous features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWUaXvwEbHlr",
        "colab_type": "code",
        "outputId": "ab2ba920-54b2-44c8-d173-18441500c556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\"\"\"\n",
        "USAGE\n",
        "results = benchmark_xgb(features, Y, num_folds=5)\n",
        "print(\"Mean MAE : \", results['test-mae-mean'].mean())\n",
        "\"\"\"\n",
        "\n",
        "results_categorical_only = benchmark_xgb(X[cat_cols], Y, num_folds=2)\n",
        "print(\"Mean MAE with only categorical features: \", results_categorical_only['test-mae-mean'].mean())\n",
        "\n",
        "results_continuous_only = benchmark_xgb(X[cont_cols], Y, num_folds=2)\n",
        "print(\"Mean MAE with only continuous features: \", results_continuous_only['test-mae-mean'].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean MAE with only categorical features:  1334.980274716999\n",
            "Mean MAE with only continuous features:  1915.3965111769992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA4edAykhVgs",
        "colab_type": "text"
      },
      "source": [
        "Since the last cell took pretty long to run on colab, I'll document it here:  \n",
        "Mean MAE with only categorical features:  1334.980274716999  \n",
        "Mean MAE with only continuous features:  1915.3965111769992  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IDt5pzAhh3H",
        "colab_type": "text"
      },
      "source": [
        "# <br>  \n",
        "\n",
        "### We will now try to reduce the dimensions of the features using PCA and see if the mean MAE improves/deteriorates\n",
        "### Choosing n_components so as to retain 95~99% variance of the features\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh-q4sWghzrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b247a70-fc97-4a8a-ef2a-4a0021d364ae"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "retain_ratio = 0.99\n",
        "\n",
        "\n",
        "def get_num_components(singular_values, retain_ratio = retain_ratio):\n",
        "  '''\n",
        "  function to choose num_components to retain for PCA\n",
        "  '''\n",
        "  k = 0\n",
        "  retain_ratio = retain_ratio\n",
        "  for i in range(len(singular_values)):\n",
        "    if sum(singular_values[:i])/sum(singular_values) < retain_ratio:\n",
        "      k -=- 1;\n",
        "    else: break;\n",
        "  return k-1\n",
        "\n",
        "\n",
        "def get_reduced_features_pca(X, retain_ratio=retain_ratio):\n",
        "  pca = PCA()\n",
        "  pca.fit(X)\n",
        "  sv = pca.singular_values_\n",
        "  k = get_num_components(sv, retain_ratio)\n",
        "  del(pca)\n",
        "  pca = PCA(n_components=k)\n",
        "  X_reduced = pca.fit_transform(X)  # all continuous features reduced after PCA\n",
        "  print(\"Retaining {}% variance with {} components from PCA (out of a total of {} features)\".format(\n",
        "                                                                retain_ratio*100, k, X.shape[1]))\n",
        "  return X_reduced\n",
        "\n",
        "\n",
        "X_cat_reduced = get_reduced_features_pca(X[cat_cols])   # get reduced features for categorical features\n",
        "X_cont_reduced = get_reduced_features_pca(X[cont_cols]) # get reduced features for continuous features"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retaining 99.0% variance with 74 components from PCA (out of a total of 116 features)\n",
            "Retaining 99.0% variance with 12 components from PCA (out of a total of 14 features)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO8o9ddSlB4k",
        "colab_type": "text"
      },
      "source": [
        "### We now see the CV scored on reduced dimensions features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV9mem60iV42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6cea197f-b5f2-49a7-e938-98b8c3a206e9"
      },
      "source": [
        "results_categorical_only = benchmark_xgb(X_cat_reduced, Y, num_folds=2)\n",
        "print(\"Mean MAE with reduced categorical features: \", results_categorical_only['test-mae-mean'].mean())\n",
        "\n",
        "results_continuous_only = benchmark_xgb(X_cont_reduced, Y, num_folds=2)\n",
        "print(\"Mean MAE with reduced continuous features: \", results_continuous_only['test-mae-mean'].mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean MAE with reduced categorical features:  1367.4354515439989\n",
            "Mean MAE with reduced continuous features:  1928.2954844269982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSRhXLDQLC38",
        "colab_type": "text"
      },
      "source": [
        "# <br>  \n",
        "### That did not work out well enough, we use some other tests to discard a few features.\n",
        "\n",
        "\n",
        "### Using f_regression and mutual_information_regression from sklearn to get scores for features. The features that do not score well on both these tests will be discarded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utioOV5Io-1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5b301074-ede9-47f6-f188-8ffe53dbe837"
      },
      "source": [
        "    \n",
        "from sklearn.feature_selection     import    f_regression, mutual_info_regression\n",
        "\n",
        "# f_regression\n",
        "##############\n",
        "f_reg_res = {}\n",
        "fval, pval = f_regression(X, Y)\n",
        "for i,c in enumerate(X.columns):\n",
        "  f_reg_res[c] = fval[i]\n",
        "\n",
        "# sort the features according to f_regression scores\n",
        "sorted_res = [[k,v] for k, v in sorted(f_reg_res.items(), key=lambda item: item[1])]\n",
        "sorted(sorted_res, key = lambda x: x[1])\n",
        "\n",
        "# remove features that scored too low\n",
        "high_score_features_F = [x[0] for x in list(filter(lambda x: x[1]>100, sorted_res))]\n",
        "print(\"features with f_regression score > 100\")\n",
        "print(high_score_features_F)\n",
        "\n",
        "\n",
        "\n",
        "# mutual_information\n",
        "####################\n",
        "# sampling a subset of data, as mutual_info calculation is intensive\n",
        "sample = train_data.sample(10000)\n",
        "x = sample.iloc[:,:-1]\n",
        "y = sample.iloc[:,-1]\n",
        "\n",
        "mutinf_res = {}\n",
        "mi = mutual_info_regression(x, y)\n",
        "for i,c in enumerate(X.columns):\n",
        "  mutinf_res[c] = mi[i]\n",
        "\n",
        "# sort the features according to mutual_information scores\n",
        "sorted_res = [[k,v] for k, v in sorted(mutinf_res.items(), key=lambda item: item[1])]\n",
        "sorted(sorted_res, key = lambda x: x[1])\n",
        "\n",
        "# remove features that scored too low\n",
        "high_score_features_MI = [x[0] for x in list(filter(lambda x: x[1]>0.001, sorted_res))]\n",
        "print(\"features with mutual_information score > 100\")\n",
        "print(high_score_features_MI)\n",
        "\n",
        "\n",
        "# get intersection of features which score high on both of these tests\n",
        "# i.e. we are discarding features that did not do well in both the tests\n",
        "common_features_union = list(set(high_score_features_F).union(set(high_score_features_MI)))\n",
        "print(\"# feautres selected: \", common_features_union.__len__())\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features with f_regression score > 100\n",
            "['cat32', 'cat49', 'cat114', 'cat112', 'cat61', 'cont8', 'cat20', 'cat34', 'cat52', 'cat104', 'cat83', 'cat116', 'cat99', 'cat51', 'cat19', 'cat47', 'cont4', 'cat58', 'cat67', 'cont6', 'cat18', 'cat84', 'cat59', 'cat33', 'cat95', 'cat46', 'cat43', 'cat44', 'cat30', 'cat53', 'cat26', 'cat78', 'cat66', 'cat100', 'cat65', 'cat71', 'cat106', 'cat45', 'cat75', 'cat17', 'cat85', 'cat29', 'cat102', 'cat8', 'cat41', 'cat76', 'cat25', 'cat24', 'cat94', 'cat38', 'cont12', 'cont11', 'cat14', 'cat82', 'cat4', 'cat5', 'cat50', 'cont3', 'cat105', 'cat6', 'cont7', 'cat28', 'cat40', 'cont2', 'cat111', 'cat103', 'cat73', 'cat36', 'cat23', 'cat90', 'cat16', 'cat3', 'cat9', 'cat13', 'cat1', 'cat11', 'cat72', 'cat2', 'cat81', 'cat89', 'cat7', 'cat10', 'cat12', 'cat57', 'cat87', 'cat101', 'cat79', 'cat80']\n",
            "features with mutual_information score > 100\n",
            "['cat18', 'cat19', 'cat52', 'cat72', 'cat48', 'cat46', 'cat47', 'cat31', 'cat79', 'cat89', 'cat97', 'cat42', 'cat67', 'cat105', 'cat87', 'cont5', 'cat99', 'cat1', 'cat96', 'cat15', 'cat28', 'cont6', 'cat26', 'cat110', 'cat86', 'cat27', 'cont14', 'cat54', 'cat93', 'cat84', 'cat30', 'cat29', 'cat45', 'cat9', 'cat39', 'cat109', 'cat103', 'cat111', 'cat76', 'cat77', 'cont4', 'cat95', 'cat41', 'cat113', 'cont1', 'cat51', 'cat24', 'cat6', 'cat5', 'cat98', 'cat7', 'cont2', 'cat107', 'cat83', 'cat37', 'cat92', 'cat17', 'cat74', 'cat104', 'cont3', 'cat90', 'cont13', 'cat112', 'cat8', 'cat4', 'cont12', 'cat91', 'cat14', 'cat58', 'cat73', 'cat12', 'cat10', 'cat3', 'cat115', 'cat2', 'cat11', 'cat82', 'cat13', 'cat88', 'cat101', 'cat102', 'cat80', 'cat81']\n",
            "# feautres selected:  115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n97n9csALK9i",
        "colab_type": "text"
      },
      "source": [
        "### MAE scores with chosen features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ7z0dCGr3Ep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8ac55859-45db-4b45-cb2b-9cee27479095"
      },
      "source": [
        "results = benchmark_xgb(X[common_features_union], Y, num_folds=2)\n",
        "print(\"Mean MAE with chosen feautures: \", results['test-mae-mean'].mean())\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean MAE with chosen feautures:  1312.4079062540006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeziVKTaLuR_",
        "colab_type": "text"
      },
      "source": [
        "## This is by far the best MAE we got with any subset of features.  \n",
        "## We will use this subset of 116 out of 130 total feautres to train a MLP and see how it goes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHUJE_2fKW32",
        "colab_type": "text"
      },
      "source": [
        "## Using MLP with union of features that scored high in the 2 tests.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pRHuD92KmD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4782951c-7ef6-42b8-d108-5abaf1eb668f"
      },
      "source": [
        "print(\"Features that would be used: \", common_features_union)\n",
        "print(\"# features: \", common_features_union.__len__())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features that would be used:  ['cat39', 'cat97', 'cat115', 'cat78', 'cat34', 'cat23', 'cat1', 'cat51', 'cat110', 'cat91', 'cat75', 'cont4', 'cat81', 'cat50', 'cat53', 'cat25', 'cat87', 'cat49', 'cat33', 'cat46', 'cat109', 'cat19', 'cat77', 'cat29', 'cat107', 'cat48', 'cat65', 'cat100', 'cont11', 'cat96', 'cat74', 'cat102', 'cat82', 'cat32', 'cat104', 'cont6', 'cat14', 'cat10', 'cat59', 'cat88', 'cat76', 'cat16', 'cat4', 'cat11', 'cat31', 'cat111', 'cat61', 'cat80', 'cat84', 'cat90', 'cat89', 'cat79', 'cat44', 'cat57', 'cont14', 'cat9', 'cont8', 'cat113', 'cat28', 'cont12', 'cat101', 'cat86', 'cat47', 'cat93', 'cat103', 'cat40', 'cat36', 'cat24', 'cat38', 'cat67', 'cat12', 'cat66', 'cat5', 'cat15', 'cat85', 'cont2', 'cat13', 'cat112', 'cat114', 'cat43', 'cat73', 'cat92', 'cat2', 'cat54', 'cat6', 'cat45', 'cont5', 'cat41', 'cat42', 'cat7', 'cat37', 'cat58', 'cat105', 'cat3', 'cat95', 'cat83', 'cat98', 'cat116', 'cat27', 'cat20', 'cat30', 'cat71', 'cat17', 'cat52', 'cont7', 'cont3', 'cont1', 'cat26', 'cat106', 'cat8', 'cat72', 'cat99', 'cont13', 'cat18', 'cat94']\n",
            "# features:  115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSHaQh-NKtlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, LeakyReLU\n",
        "from keras.preprocessing import text\n",
        "from keras import utils\n",
        "from tensorflow.nn import leaky_relu\n",
        "\n",
        "# set hyperparameters for MLP\n",
        "class NN:\n",
        "    def __init__(self):\n",
        "        self.in_shape = common_features_union.__len__()\n",
        "        self.num_layers = 3\n",
        "        self.nodes = [2048,1024, 1]\n",
        "        self.activations = ['relu', 'relu', 'relu']\n",
        "        self.dropouts = [0.2,0.15,0]\n",
        "        self.loss = 'mean_squared_logarithmic_error'\n",
        "        self.optimizer = keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "\n",
        "\n",
        "def sequential_MLP(nn):\n",
        "    model = Sequential()\n",
        "    for i in range(nn.num_layers):\n",
        "        if i==0: # add input shape if first layer\n",
        "            model.add(Dense(nn.nodes[i], activation=nn.activations[i], input_shape=(nn.in_shape,) ))\n",
        "        else:\n",
        "            model.add(Dense(nn.nodes[i], activation=nn.activations[i]))\n",
        "        if(nn.dropouts[i] != 0): # skip adding dropout if dropout == 0\n",
        "            model.add(Dropout(rate=nn.dropouts[i]))            \n",
        "    model.compile(optimizer=nn.optimizer, loss=nn.loss, metrics=['mae'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGIHbVUhgc15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "652a7496-1d8c-43ce-9ac9-6a82ae5e31a1"
      },
      "source": [
        "\n",
        "\n",
        "nn = NN()\n",
        "model = sequential_MLP(nn)\n",
        "\n",
        "\n",
        "for i in range(71):\n",
        "  if i%10 == 0: verbose=True\n",
        "  else: verbose = False\n",
        "  model.fit(X[common_features_union], Y, epochs=1, batch_size=512, validation_split=0.25, verbose=verbose)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 3s 22us/step - loss: 0.9060 - mean_absolute_error: 1724.5766 - val_loss: 0.3869 - val_mean_absolute_error: 1399.6149\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 14us/step - loss: 0.3401 - mean_absolute_error: 1255.7799 - val_loss: 0.3295 - val_mean_absolute_error: 1231.0664\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 14us/step - loss: 0.3311 - mean_absolute_error: 1234.8959 - val_loss: 0.3204 - val_mean_absolute_error: 1220.9107\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 14us/step - loss: 0.3252 - mean_absolute_error: 1222.7264 - val_loss: 0.3619 - val_mean_absolute_error: 1288.6681\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 14us/step - loss: 0.3207 - mean_absolute_error: 1214.3922 - val_loss: 0.3322 - val_mean_absolute_error: 1225.8456\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 14us/step - loss: 0.3181 - mean_absolute_error: 1208.2197 - val_loss: 0.3140 - val_mean_absolute_error: 1202.2561\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 14us/step - loss: 0.3145 - mean_absolute_error: 1202.6634 - val_loss: 0.3170 - val_mean_absolute_error: 1194.7875\n",
            "Train on 141238 samples, validate on 47080 samples\n",
            "Epoch 1/1\n",
            "141238/141238 [==============================] - 2s 13us/step - loss: 0.3126 - mean_absolute_error: 1197.5528 - val_loss: 0.3106 - val_mean_absolute_error: 1199.7176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANpJAmvOVcmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(test_data[common_features_union])\n",
        "submission['loss'] = test_predictions\n",
        "submission.to_csv(objects_dir+'submission_5.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGgH8WM4vrA-",
        "colab_type": "text"
      },
      "source": [
        "### This model got me a MAE of 1160 on the public test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgZ2IDm7wB3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}